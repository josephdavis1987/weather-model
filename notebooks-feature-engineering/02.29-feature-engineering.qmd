---
title: "02.25 - Feature Engineering (A‐only)"
format: html
jupyter: python3
---

## 1. Load & Tag A/B

```{python}
import duckdb
import pandas as pd
from pathlib import Path

project_root    = Path().resolve().parent
db_path         = project_root / "weather.duckdb"

in_sample_start = "2000-01-01"
in_sample_end   = "2010-12-31"

# Pull with a sample flag
con = duckdb.connect(str(db_path))
df = con.execute(f"""
  SELECT
    *,
    CASE
      WHEN date BETWEEN '{in_sample_start}' AND '{in_sample_end}' THEN 'A'
      ELSE 'B'
    END AS sample
  FROM weather
""").fetchdf()
con.close()

# Fix types and compute day_of_year
df["date"]        = pd.to_datetime(df["date"])
df["day_of_year"] = df["date"].dt.dayofyear

# Working copy
df_feat = df.copy()

df_feat.columns

```

## 2. Global Clean (drop sentinels & any rows with missing)
```{python}

import numpy as np

# Replace sentinel -999 with NaN everywhere
df_feat.replace(-999, np.nan, inplace=True)

# Drop any row with *any* missing value  
# (this removes those bad rows from both A & B before feature engineering)
df_feat.dropna(inplace=True)

print("After global clean:", df_feat.shape)
print(df_feat["sample"].value_counts())

```

## 3. Extract A‐sample & Compute Seasonal Averages
```{python}
# 3a) A‐sample
df_A = df_feat[df_feat["sample"] == "A"].copy()

# 3b) Seasonal‐avg helper
def seasonal_avg_dfs(df, exclude=None):
    if exclude is None:
        exclude = {"date","day_of_year","location","lat","lon","sample"}
    tbls, feats = [], [c for c in df.columns if c not in exclude]
    for col in feats:
        tbl = (
            df
            .groupby(["location","day_of_year"])[col]
            .mean()
            .reset_index(name=f"{col}_seasonal_avg")
        )
        tbls.append(tbl)
    return tbls

exclude = {"date","day_of_year","location","lat","lon","sample"}
seasonal_tables = seasonal_avg_dfs(df_A, exclude)

# 3c) Merge back onto full df_feat
for tbl in seasonal_tables:
    df_feat = df_feat.merge(tbl, on=["location","day_of_year"], how="left")

print("Seasonal cols:", [c for c in df_feat.columns if c.endswith("_seasonal_avg")])

```

## 4. Compute Rolling Means (A‐only)
```{python}

# Define which columns & windows
roll_cols    = ["t2m","t2m_max","t2m_min","prectotcorr"]
roll_windows = [7,30]

# Sort A‐sample once for rolling
df_A = df_A.sort_values(["location","date"]).reset_index(drop=True)

for col in roll_cols:
    for w in roll_windows:
        name = f"{col}_{w}d_avg"
        df_A[name] = (
            df_A
            .groupby("location")[col]
            .transform(lambda x: x.rolling(w, min_periods=1).mean())
        )
        # merge back by location+date
        df_feat = df_feat.merge(
            df_A[["location","date",name]],
            on=["location","date"],
            how="left"
        )

print("Rolling cols:", [c for c in df_feat.columns if c.endswith(("7d_avg","30d_avg"))])


```


## 5. Split into Train/Test
```{python}

# 5a) Train = the in-sample window
df_train = df_feat[df_feat["sample"] == "A"].copy()

# 5b) Test  = only the dates *after* in_sample_end
#         (so we drop any rows before the training window)
in_end = pd.to_datetime(in_sample_end)
df_test = df_feat[df_feat["date"] > in_end].copy()

print("Train:", df_train.shape)
print("Test: ", df_test.shape)

```

## 6. Example Plot (A only)
```{python}

import plotly.express as px

loc    = "Chattanooga"
subset = df_train[df_train["location"] == loc]

fig = px.line(
    subset,
    x="date",
    y=["t2m_max","t2m_max_seasonal_avg","t2m_max_7d_avg","t2m_max_30d_avg"],
    labels={"value":"T₂ₘₐₓ","variable":"Feature"},
    title=f"{loc} – Observed vs Seasonal & Rolling (A)"
)
fig.show()

```

7. Export to Parquet
```{python}
from pathlib import Path

data_dir = project_root/"data"
train_path = data_dir/"weather_train.parquet"
test_path  = data_dir/"weather_test.parquet"

df_train.to_parquet(train_path, index=False)
df_test.to_parquet(test_path,  index=False)

print("Wrote:", train_path, test_path)

```



