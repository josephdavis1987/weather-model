---
title: "03.65 – XGBoost Cascading Multi-Output Forecasts (All Surrounding Cities)"
format: html
jupyter: python3
----------------

## 0. Parameters

```{python}
from pathlib import Path

# ─── Editable parameters ─────────────────────────────────────────────
target_city_name = "Chattanooga" # The city we are forecasting for
train_start      = "2000-01-01"  # inclusive
train_end        = "2022-12-31"  # inclusive
test_start       = "2023-01-01"  # inclusive
test_end         = "2024-12-31"  # inclusive
forecast_horizon = None          # not used; we forecast exactly test range

# MODIFIED: All remaining surrounding cities added
# Surrounding cities to pull data from for cross-city features
# Ensure these city names exactly match your 'location' column in DuckDB
surrounding_cities = ["Scottsboro", "Jasper", "Winchester", 
                      "Cleveland", "Dalton", "Athens", "Fort Payne", "Dayton", "Ringgold"] 

# ─── Internal paths ─────────────────────────────────────────────────
project_root = Path().resolve().parent
db_path      = project_root / "weather.duckdb"

assert db_path.exists(), f"DuckDB not found at {db_path}"
print(f"DB path:       {db_path}")
print(f"Target City:   {target_city_name}")
print(f"Surrounding Cities for Features: {surrounding_cities}")
print(f"Train window:  {train_start} → {train_end}")
print(f"Test window:   {test_start} → {test_end}")
```


## 1. Load & Clean Data

```{python}
import duckdb
import pandas as pd

# List of all cities we need to load data for
all_cities_to_load = [target_city_name] + surrounding_cities

# 1a) Query raw columns from DuckDB for ALL relevant cities
query = f"""
SELECT
  date,
  location,
  t2m,
  t2m_max,
  t2m_min,
  t2m_range,
  dewpoint,
  rh2m,
  ws10m,
  wd10m,
  ps,
  allsky_sw_dwn,
  allsky_lw_dwn,
  prectotcorr
FROM weather
WHERE location IN ({str(all_cities_to_load)[1:-1]}) -- Dynamically include all cities
  AND date BETWEEN '{train_start}' AND '{test_end}'
ORDER BY date, location -- Crucial for correct groupby().shift() operations later
"""
# Load data for all selected cities
df_all_cities = duckdb.connect(str(db_path)).execute(query).fetchdf()

# 1b) Convert and drop sentinel values
numeric_cols = [
    "t2m","t2m_max","t2m_min","t2m_range","dewpoint","rh2m","ws10m",
    "wd10m","ps","allsky_sw_dwn","allsky_lw_dwn","prectotcorr"
]
df_all_cities["date"] = pd.to_datetime(df_all_cities["date"])
df_all_cities = df_all_cities[(df_all_cities[numeric_cols]!= -999).all(axis=1)]

print(f"After initial cleaning (all cities): {df_all_cities.shape[0]} rows")
print(f"Loaded unique locations: {df_all_cities['location'].unique()}")
df_all_cities.head()
```

## 2. Feature Engineering

```{python}
import numpy as np

# --- 2a/2b: Apply base feature engineering to all cities' data ---
df_all_cities["date_ordinal"] = df_all_cities["date"].map(pd.Timestamp.toordinal)
df_all_cities["day_of_year"] = df_all_cities["date"].dt.dayofyear
df_all_cities["doy_sin"] = np.sin(2 * np.pi * df_all_cities["day_of_year"] / 365)
df_all_cities["doy_cos"] = np.cos(2 * np.pi * df_all_cities["day_of_year"] / 365)

# --- NEW: Additional Calculable Features (for ALL cities) ---
df_all_cities['t2m_ratio_to_t2m_min'] = df_all_cities['t2m'] / df_all_cities['t2m_min']
df_all_cities.replace([np.inf, -np.inf], np.nan, inplace=True) 

df_all_cities['t2m_dewpoint_spread'] = df_all_cities['t2m'] - df_all_cities['dewpoint']
df_all_cities['t2m_avg_from_max_min'] = (df_all_cities['t2m_max'] + df_all_cities['t2m_min']) / 2
df_all_cities['ps_change_24hr'] = df_all_cities.groupby('location')['ps'].diff(periods=1) # Groupby needed for multi-city
df_all_cities['wind_u'] = df_all_cities['ws10m'] * np.sin(np.radians(df_all_cities['wd10m']))
df_all_cities['wind_v'] = df_all_cities['ws10m'] * np.cos(np.radians(df_all_cities['wd10m']))
df_all_cities['t2m_range_normalized'] = df_all_cities['t2m_range'] / df_all_cities['t2m']
df_all_cities.replace([np.inf, -np.inf], np.nan, inplace=True)


# --- Generate Intra-City Lag Features (for ALL cities) ---
intra_city_dynamic_features = [
    "t2m", "t2m_min", "t2m_max", "t2m_range", "dewpoint", "rh2m",
    "ws10m", "wd10m", "ps", "allsky_sw_dwn", "allsky_lw_dwn", "prectotcorr",
    "t2m_ratio_to_t2m_min", "t2m_dewpoint_spread", "t2m_avg_from_max_min",
    "ps_change_24hr", "wind_u", "wind_v", "t2m_range_normalized"
]
intra_city_lags = [1, 2, 3, 4, 5, 6, 7] 

for feature in intra_city_dynamic_features:
    for lag in intra_city_lags:
        new_col_name = f"{feature}_lag_{lag}"
        df_all_cities[new_col_name] = df_all_cities.groupby('location')[feature].shift(lag)


# --- NEW: Generate Cross-City Lag Features (for TARGET_CITY only) ---
cross_city_features_to_lag = ["t2m", "ps", "wind_u", "wind_v", "t2m_avg_from_max_min"]
cross_city_lags = [1, 2] 

# Create a temporary DataFrame to hold cross-city features for merging
df_target_city_features = df_all_cities[df_all_cities['location'] == target_city_name].copy()

for other_city in surrounding_cities:
    df_other_city = df_all_cities[df_all_cities['location'] == other_city].copy()
    
    for feature in cross_city_features_to_lag:
        for lag in cross_city_lags:
            original_feature_name = feature
            lagged_col_name = f"{other_city.lower()}_{original_feature_name}_lag_{lag}"
            
            lagged_data = df_other_city[['date', original_feature_name]].copy()
            lagged_data['date'] = lagged_data['date'] + pd.Timedelta(days=lag) 
            lagged_data = lagged_data.rename(columns={original_feature_name: lagged_col_name})
            
            df_target_city_features = pd.merge(
                df_target_city_features,
                lagged_data[['date', lagged_col_name]],
                on='date',
                how='left' 
            )

# The final 'df' for training and testing is now just the target city's data with all its features
df = df_target_city_features.copy()

# --- NEW: Generate Rolling Window Features (for TARGET_CITY only) ---
rolling_features_to_calculate = [
    "t2m", "dewpoint", "ps", "prectotcorr", "t2m_avg_from_max_min"
]
rolling_windows = [3, 7] # 3-day and 7-day windows
rolling_stats = ['mean', 'std'] # Mean and Standard Deviation

# Ensure the DataFrame is sorted by date for correct rolling calculations
df = df.sort_values(by='date').reset_index(drop=True)

for feature in rolling_features_to_calculate:
    for window in rolling_windows:
        rolling_series = df[feature].rolling(window=window, min_periods=1) 
        
        if 'mean' in rolling_stats:
            df[f"{feature}_roll_mean_{window}d"] = rolling_series.mean()
        if 'std' in rolling_stats:
            df[f"{feature}_roll_std_{window}d"] = rolling_series.std()


# --- MODIFIED: Target columns are now based on t2m (1, 2, 3, 4, 5 days) ---
df["t2m_1_day_later"] = df["t2m"].shift(-1)
df["t2m_2_days_later"] = df["t2m"].shift(-2)
df["t2m_3_days_later"] = df["t2m"].shift(-3)
df["t2m_4_days_later"] = df["t2m"].shift(-4)
df["t2m_5_days_later"] = df["t2m"].shift(-5)

# Build the comprehensive feature_cols list (base + intra-city lags + cross-city lags + rolling windows)
base_feature_cols = [
    "date_ordinal", "day_of_year", "doy_sin", "doy_cos",
    "t2m", "t2m_min", "t2m_max", "t2m_range", "dewpoint", "rh2m",
    "ws10m", "wd10m", "ps", "allsky_sw_dwn", "allsky_lw_dwn", "prectotcorr",
    "t2m_ratio_to_t2m_min", "t2m_dewpoint_spread", "t2m_avg_from_max_min",
    "ps_change_24hr", "wind_u", "wind_v", "t2m_range_normalized"
]

# Initialize feature_cols. This list will be dynamically augmented in Section 4.
initial_feature_cols = list(base_feature_cols) 

for feature in intra_city_dynamic_features:
    for lag in intra_city_lags:
        initial_feature_cols.append(f"{feature}_lag_{lag}")

for other_city in surrounding_cities:
    for feature in cross_city_features_to_lag:
        for lag in cross_city_lags:
            initial_feature_cols.append(f"{other_city.lower()}_{feature}_lag_{lag}")


# Add all generated rolling window features
for feature in rolling_features_to_calculate:
    for window in rolling_windows:
        if 'mean' in rolling_stats:
            initial_feature_cols.append(f"{feature}_roll_mean_{window}d")
        if 'std' in rolling_stats:
            initial_feature_cols.append(f"{feature}_roll_std_{window}d")


# Define target columns for all 5 horizons
target_cols = [
    "t2m_1_day_later",
    "t2m_2_days_later", 
    "t2m_3_days_later",
    "t2m_4_days_later", 
    "t2m_5_days_later"
]

# --- Handle NaNs from shifting targets and new calculations ---
all_cols_to_check_for_nan = list(target_cols) 
all_cols_to_check_for_nan.extend(initial_feature_cols) 


original_rows = df.shape[0]
df.dropna(subset=all_cols_to_check_for_nan, inplace=True)
print(f"Dropped {original_rows - df.shape[0]} rows due to NaNs from shifting targets and new calculations.")

print(f"Final features count (initial pool): {len(initial_feature_cols)}")
print("Targets: ", target_cols)
df.tail()
```

## 3. Train/Test Split

```{python}
# 3a) Boolean masks
mask_train = (df["date"] >= train_start) & (df["date"] <= train_end)
mask_test  = (df["date"] >= test_start)  & (df["date"] <= test_end)

train_df = df[mask_train].reset_index(drop=True)
test_df  = df[mask_test].reset_index(drop=True)

print("Train rows:", train_df.shape[0])
print("Test rows: ", test_df.shape[0])
```

## 4. Train Cascading XGBoost Models

```{python}
from xgboost import XGBRegressor
from sklearn.base import clone

# Initialize a dictionary to store each trained model
models = {} 

# Store predictions to be used as features in subsequent steps
train_pred_features_df = pd.DataFrame(index=train_df.index) 
test_pred_features_df = pd.DataFrame(index=test_df.index)

# Define the base XGBoost model
xgb_base_model = XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    random_state=0,
    objective='reg:absoluteerror'
)

# Deep copy of initial_feature_cols to modify it for each step
current_feature_cols_for_training = list(initial_feature_cols) 

for i, target_col in enumerate(target_cols):
    print(f"\n--- Training Model for {target_col} ---")
    
    # Prepare training data for the current model
    iX_train = train_df[current_feature_cols_for_training]
    iy_train = train_df[target_col]
    
    # Clone the base model to ensure a fresh start for each target
    model = clone(xgb_base_model) 
    
    print(f"Features used for {target_col}: {len(current_feature_cols_for_training)} features")
    model.fit(iX_train, iy_train)
    models[target_col] = model # Store the trained model

    # --- Generate predictions for the next step's features ---
    # Generate predictions on the TRAINING set (for subsequent model training)
    train_preds = model.predict(train_df[current_feature_cols_for_training])
    new_pred_feature_name = f"predicted_{target_col}"
    train_pred_features_df[new_pred_feature_name] = train_preds
    
    # Generate predictions on the TEST set (for final evaluation)
    test_preds = model.predict(test_df[current_feature_cols_for_training])
    test_pred_features_df[new_pred_feature_name] = test_preds

    # --- Add prediction as a new feature for the NEXT model if not the last target ---
    if i < len(target_cols) - 1:
        # Add the generated predictions as features for the next iteration's feature set
        current_feature_cols_for_training.append(new_pred_feature_name)
        
        # Manually add the new feature to train_df and test_df for the next loop's access
        train_df[new_pred_feature_name] = train_pred_features_df[new_pred_feature_name]
        test_df[new_pred_feature_name] = test_pred_features_df[new_pred_feature_name]


print("\nAll cascading models trained.")
```

## 5. Forecast & Evaluate

```{python}
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

# df_eval will contain true and predicted values for all horizons
df_eval = pd.DataFrame({"date": test_df["date"]})

# Loop through each target to collect true values and predictions from the final models
for target_col in target_cols:
    # True values are always from the original test_df
    df_eval[f"y_true_{target_col}"] = test_df[target_col]
    
    # Predicted values are stored in test_pred_features_df from Section 4
    df_eval[f"y_pred_{target_col}"] = test_pred_features_df[f"predicted_{target_col}"]


# Calculate metrics for each target
for target_col in target_cols:
    y_true = df_eval[f"y_true_{target_col}"]
    y_pred = df_eval[f"y_pred_{target_col}"]

    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae  = mean_absolute_error(y_true, y_pred)
    print(f"\nMetrics for {target_col}:")
    print(f"  RMSE: {rmse:.3f}, MAE: {mae:.3f}")

df_eval.head()
```

## 6.0 Plot Results (All Series)

```{python}
import plotly.express as px
import pandas as pd

# Define plotting colors (expanded for 5 horizons)
base_blue_1 = "#007BFF" # Darker blue
base_blue_2 = "#3399FF" # Slightly lighter
base_blue_3 = "#66B2FF" # Medium blue
base_blue_4 = "#99CCFF" # Lighter
base_blue_5 = "#ADD8FF" # Lightest blue

plot_df_list = []

# Add Actual (Today's Mean Temp)
plot_df_list.append(
    df[["date", "t2m"]].assign(series="Actual (Today's Mean Temp)")
    .rename(columns={"t2m": "temperature"})
)

# Process training data
for target_col in target_cols:
    horizon_name = target_col.replace('t2m_', '').replace('_later', ' day(s)')
    plot_df_list.append(
        train_df[["date", target_col]].assign( 
            series=f"Train (t2m_{horizon_name})"
        ).rename(columns={target_col: "temperature"})
    )

# Process test data (Actuals and Predictions)
for target_col in target_cols:
    horizon_name = target_col.replace('t2m_', '').replace('_later', ' day(s)')
    
    # Test Actual
    plot_df_list.append(
        df_eval[["date", f"y_true_{target_col}"]].assign(
            series=f"Test Actual ({horizon_name})"
        ).rename(columns={f"y_true_{target_col}": "temperature"})
    )
    
    # Test Prediction
    plot_df_list.append(
        df_eval[["date", f"y_pred_{target_col}"]].assign(
            series=f"Test Pred ({horizon_name})"
        ).rename(columns={f"y_pred_{target_col}": "temperature"})
    )

plot_df = pd.concat(plot_df_list, ignore_index=True)


# Define color map for all series
color_map = {
    "Actual (Today's Mean Temp)": "black",
    "Train (t2m_1 day(s))": "#7a9cb2",
    "Train (t2m_2 day(s))": "#8bb0c4",
    "Train (t2m_3 day(s))": "#a0b7c7",
    "Train (t2m_4 day(s))": "#b5cdd2",
    "Train (t2m_5 day(s))": "#c5d2db",
    "Test Actual (1 day(s))": base_blue_1,
    "Test Actual (2 day(s))": base_blue_2,
    "Test Actual (3 day(s))": base_blue_3,
    "Test Actual (4 day(s))": base_blue_4,
    "Test Actual (5 day(s))": base_blue_5, 
    "Test Pred (1 day(s))": base_blue_1, 
    "Test Pred (2 day(s))": base_blue_2,
    "Test Pred (3 day(s))": base_blue_3,
    "Test Pred (4 day(s))": base_blue_4,
    "Test Pred (5 day(s))": base_blue_5,
}

# Adjust shades for predictions to be slightly lighter if desired, or use dashes heavily
color_map["Test Pred (1 day(s))"] = "#3399FF"
color_map["Test Pred (2 day(s))"] = "#66CCFF"
color_map["Test Pred (3 day(s))"] = "#99CCFF"
color_map["Test Pred (4 day(s))"] = "#C5E3FF"
color_map["Test Pred (5 day(s))"] = "#E0F2FF"


line_dash_map = {
    "Actual (Today's Mean Temp)": "solid",
    "Train (t2m_1 day(s))": "dot",
    "Train (t2m_2 day(s))": "dot",
    "Train (t2m_3 day(s))": "dot",
    "Train (t2m_4 day(s))": "dot",
    "Train (t2m_5 day(s))": "dot",
    "Test Actual (1 day(s))": "solid",
    "Test Actual (2 day(s))": "solid",
    "Test Actual (3 day(s))": "solid",
    "Test Actual (4 day(s))": "solid",
    "Test Actual (5 day(s))": "solid",
    "Test Pred (1 day(s))": "dash",
    "Test Pred (2 day(s))": "dash",
    "Test Pred (3 day(s))": "dash",
    "Test Pred (4 day(s))": "dash",
    "Test Pred (5 day(s))": "dash",
}

fig = px.line(
    plot_df,
    x="date",
    y="temperature",
    color="series",
    title=f"XGBoost Baseline for {target_city_name} - Multi-Day Forecasts (Target: T2M)",
    template="plotly_white",
    color_discrete_map=color_map,
    line_dash_map=line_dash_map
)
fig.update_layout(height=600, xaxis_title="Date", yaxis_title="T2M Mean Temp (°C)")
fig.show()
```

# 6.1 plot differences

```{python}
import plotly.express as px
import pandas as pd

plot_error_df_list = []

for target_col in target_cols:
    horizon_name = target_col.replace('t2m_', '').replace('_later', ' day(s)')
    
    # Calculate the error: Test Actual - Test Prediction
    error_col = f"error_{horizon_name}"
    df_eval[error_col] = df_eval[f"y_true_{target_col}"] - df_eval[f"y_pred_{target_col}"]
    
    plot_error_df_list.append(
        df_eval[["date", error_col]].assign(
            series=f"Error ({horizon_name})"
        ).rename(columns={error_col: "error"}) # Standardize column name to 'error'
    )

plot_error_df = pd.concat(plot_error_df_list, ignore_index=True)

# Define distinct colors for the error lines (adjusted for 5 horizons)
error_color_map = {
    "Error (1 day(s))": "blue",
    "Error (2 day(s))": "#4CAF50", # A new green shade
    "Error (3 day(s))": "green",
    "Error (4 day(s))": "#FFC107", # An amber shade
    "Error (5 day(s))": "red",
}

fig_error = px.line(
    plot_error_df,
    x="date",
    y="error",
    color="series",
    title=f"Forecast Error for {target_city_name} by Horizon (Test Set - Target: T2M)",
    labels={"error": "Prediction Error (°C)", "date": "Date"}, # Customize labels
    template="plotly_white",
    color_discrete_map=error_color_map
)

# Add a horizontal line at y=0 to easily visualize positive vs. negative errors
fig_error.add_hline(y=0, line_dash="dash", line_color="grey", annotation_text="Zero Error")

fig_error.update_layout(height=600)
fig_error.show()
```

## 6.2 Feature Importance

```{python}
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Accessing feature importance from MultiOutputRegressor
# It contains a list of estimators, one for each target.
# We will loop through them to show importance for each target.

print("--- Feature Importances for Each Cascading Model ---")
for i, target_col in enumerate(target_cols):
    # Get the specific XGBoost estimator for this target
    model_for_importance = models[target_col]
    feature_importances = model_for_importance.feature_importances_

    # Reconstruct the feature list for this specific model
    # This logic is based on how current_feature_cols_for_training was built in Section 4
    model_specific_feature_cols = list(initial_feature_cols) # Start with base features
    for prev_i in range(i): # Add predicted features from earlier steps
        model_specific_feature_cols.append(f"predicted_{target_cols[prev_i]}")

    importance_df = pd.DataFrame({
        'Feature': model_specific_feature_cols, # Use the model-specific feature list
        'Importance': feature_importances
    })
    importance_df = importance_df.sort_values(by='Importance', ascending=False)

    print(f"\nFeature Importances for {target_col} Model (Target: T2M):")
    print(importance_df.head(20)) # Print top 20 features for more detail

    # Plotting the top N feature importances for each
    plt.figure(figsize=(12, 8)) # Increased height for more features
    sns.barplot(x='Importance', y='Feature', data=importance_df.head(20), palette='viridis')
    plt.title(f'Top 20 Feature Importances for {target_col} Model')
    plt.xlabel('Importance (F-score or Gain)')
    plt.ylabel('Feature')
    plt.grid(axis='x', linestyle='--', alpha=0.7)
    plt.tight_layout()
    plt.show()
```

